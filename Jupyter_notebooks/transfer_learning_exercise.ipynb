{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning_exercise.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSV5QjpqxG0l"
      },
      "source": [
        "# Tensorflow exercise \n",
        "1) Use feature-extraction to train a transfer learning model on 10% of the Food Vision data for 10 epochs using tf.keras.applications.EfficientNetB0 as the base model. Use the ModelCheckpoint callback to save the weights to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJUmZhqjyKO7",
        "outputId": "76e7347e-34b3-4b05-b36e-26054cfd9993"
      },
      "source": [
        "# lets get the helper function \n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-09 16:02:28--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-09 16:02:28 (79.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGoNsMV6x9wO"
      },
      "source": [
        "# lets import the libraries  \n",
        "\n",
        "import tensorflow as tf \n",
        "from helper_functions import create_tensorboard_callback,plot_loss_curves,unzip_data,walk_through_dir\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y3us06myfTK",
        "outputId": "e2011833-b881-4075-90e8-629474a24ff4"
      },
      "source": [
        "# Lets get the 10% food vision data \n",
        "# get 10 % of the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-09 16:02:43--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.121.128, 142.250.103.128, 108.177.120.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.121.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   152MB/s    in 1.1s    \n",
            "\n",
            "2021-10-09 16:02:44 (152 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNB0SnC6yt4j"
      },
      "source": [
        "# unzip the data into the corresponding folder \n",
        "unzip_data('10_food_classes_10_percent.zip')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9a0D3HGy5W7",
        "outputId": "5a9cf5c0-002c-49fc-ae45-97a30ab2e6ff"
      },
      "source": [
        "walk_through_dir('10_food_classes_10_percent')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDVHYMeAzFGC",
        "outputId": "32f721ce-eea8-41d7-dd59-d5a02de755a4"
      },
      "source": [
        "# create training and testing directory \n",
        "train_dir='10_food_classes_10_percent/train'\n",
        "test_dir='10_food_classes_10_percent/test'\n",
        "\n",
        "IMG_SIZE=(224,224)\n",
        "BATCH_SIZE=32\n",
        "\n",
        "train_data_10_percent=tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                              label_mode='categorical',\n",
        "                                                              image_size=IMG_SIZE,\n",
        "                                                              batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "test_data=tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                             label_mode='categorical',\n",
        "                                                             image_size=IMG_SIZE,\n",
        "                                                             batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2m0wgWv1Nnc",
        "outputId": "99e36869-4c37-4ca9-93c9-61c9b5af950e"
      },
      "source": [
        "train_data_10_percent.class_names"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ5uokHv1pes"
      },
      "source": [
        "# Data augumentation \n",
        "\n",
        "Include the data augumentation step into the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f418jeLi2jQb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# create data augumentation stage with horizontal flipping , rotations and zooms \n",
        "\n",
        "data_augumentation=keras.Sequential([\n",
        "                                     preprocessing.RandomFlip(\"horizontal\"),\n",
        "                                     preprocessing.RandomRotation(0.2),\n",
        "                                     preprocessing.RandomZoom(0.2),\n",
        "                                     preprocessing.RandomHeight(0.2),\n",
        "                                     preprocessing.RandomWidth(0.2),\n",
        "                                     # preprocessing.Rescale(1/255.)\n",
        "],name='data_augumentation')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K50T4ZlK7M9_",
        "outputId": "c57a8682-a0ee-43dd-b838-55a3b667c43c"
      },
      "source": [
        "input_shape=(224,224,3)\n",
        "base_model=tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "base_model.trainable=False \n",
        "\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "x=data_augumentation(inputs)\n",
        "\n",
        "x=base_model(x,training=False)\n",
        "\n",
        "x=tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "outputs=tf.keras.layers.Dense(len(train_data_10_percent.class_names),activation='softmax')(x)\n",
        "\n",
        "model_0=keras.Model(inputs,outputs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224), dtype=tf.float32, name='random_flip_input'), name='random_flip_input', description=\"created by layer 'random_flip_input'\"), but it was called on an input with incompatible shape (None, 224, 224, 3).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOImtIbt_t1m"
      },
      "source": [
        "checkpoint_path='ten_percent_model_checkpoints_weights/checkpoint.ckpt'\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                       save_weights_only=True,\n",
        "                                                       save_best_only=True,\n",
        "                                                       monitor='val_loss',\n",
        "                                                       verbose=1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD_de9TJ8_ln"
      },
      "source": [
        "intial_epoch=5\n",
        "model_0.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "history_0=model_0.fit(train_data_10_percent,\n",
        "            steps_per_epoch=len(train_data_10_percent),\n",
        "            validation_steps=(int(len(test_data)*0.25)),\n",
        "            validation_data=test_data,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            epochs=initial_epoch,\n",
        "            callbacks=[checkpoint_callback])\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnFxNdiFCYlS",
        "outputId": "096aa235-4336-4177-97a4-6b2cdbdf8e87"
      },
      "source": [
        "model_0.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "data_augumentation (Sequenti (None, None, 224)         0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                12810     \n",
            "=================================================================\n",
            "Total params: 4,062,381\n",
            "Trainable params: 12,810\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boZ8KYtN-5lw",
        "outputId": "4506d0f9-3b6c-4a88-9054-be82e1705737"
      },
      "source": [
        "model_0.evaluate(test_data)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 11s 135ms/step - loss: 0.4979 - accuracy: 0.8404\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49787065386772156, 0.840399980545044]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbVRzlMcBg-o"
      },
      "source": [
        "Fine-tune the last 20 layers of the base model you trained in 2 for another 10 epochs. How did it go?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwSLjq5WBoDe",
        "outputId": "1005bbe3-199b-4b62-d0b2-6c14d6428aa7"
      },
      "source": [
        "# list all the layers and show their status if they are trainable\n",
        "for layer_number, layers in enumerate(base_model.layers):\n",
        "  print(layer_number,layers.name,layers.trainable)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_8 False\n",
            "1 rescaling_4 False\n",
            "2 normalization_4 False\n",
            "3 stem_conv_pad False\n",
            "4 stem_conv False\n",
            "5 stem_bn False\n",
            "6 stem_activation False\n",
            "7 block1a_dwconv False\n",
            "8 block1a_bn False\n",
            "9 block1a_activation False\n",
            "10 block1a_se_squeeze False\n",
            "11 block1a_se_reshape False\n",
            "12 block1a_se_reduce False\n",
            "13 block1a_se_expand False\n",
            "14 block1a_se_excite False\n",
            "15 block1a_project_conv False\n",
            "16 block1a_project_bn False\n",
            "17 block2a_expand_conv False\n",
            "18 block2a_expand_bn False\n",
            "19 block2a_expand_activation False\n",
            "20 block2a_dwconv_pad False\n",
            "21 block2a_dwconv False\n",
            "22 block2a_bn False\n",
            "23 block2a_activation False\n",
            "24 block2a_se_squeeze False\n",
            "25 block2a_se_reshape False\n",
            "26 block2a_se_reduce False\n",
            "27 block2a_se_expand False\n",
            "28 block2a_se_excite False\n",
            "29 block2a_project_conv False\n",
            "30 block2a_project_bn False\n",
            "31 block2b_expand_conv False\n",
            "32 block2b_expand_bn False\n",
            "33 block2b_expand_activation False\n",
            "34 block2b_dwconv False\n",
            "35 block2b_bn False\n",
            "36 block2b_activation False\n",
            "37 block2b_se_squeeze False\n",
            "38 block2b_se_reshape False\n",
            "39 block2b_se_reduce False\n",
            "40 block2b_se_expand False\n",
            "41 block2b_se_excite False\n",
            "42 block2b_project_conv False\n",
            "43 block2b_project_bn False\n",
            "44 block2b_drop False\n",
            "45 block2b_add False\n",
            "46 block3a_expand_conv False\n",
            "47 block3a_expand_bn False\n",
            "48 block3a_expand_activation False\n",
            "49 block3a_dwconv_pad False\n",
            "50 block3a_dwconv False\n",
            "51 block3a_bn False\n",
            "52 block3a_activation False\n",
            "53 block3a_se_squeeze False\n",
            "54 block3a_se_reshape False\n",
            "55 block3a_se_reduce False\n",
            "56 block3a_se_expand False\n",
            "57 block3a_se_excite False\n",
            "58 block3a_project_conv False\n",
            "59 block3a_project_bn False\n",
            "60 block3b_expand_conv False\n",
            "61 block3b_expand_bn False\n",
            "62 block3b_expand_activation False\n",
            "63 block3b_dwconv False\n",
            "64 block3b_bn False\n",
            "65 block3b_activation False\n",
            "66 block3b_se_squeeze False\n",
            "67 block3b_se_reshape False\n",
            "68 block3b_se_reduce False\n",
            "69 block3b_se_expand False\n",
            "70 block3b_se_excite False\n",
            "71 block3b_project_conv False\n",
            "72 block3b_project_bn False\n",
            "73 block3b_drop False\n",
            "74 block3b_add False\n",
            "75 block4a_expand_conv False\n",
            "76 block4a_expand_bn False\n",
            "77 block4a_expand_activation False\n",
            "78 block4a_dwconv_pad False\n",
            "79 block4a_dwconv False\n",
            "80 block4a_bn False\n",
            "81 block4a_activation False\n",
            "82 block4a_se_squeeze False\n",
            "83 block4a_se_reshape False\n",
            "84 block4a_se_reduce False\n",
            "85 block4a_se_expand False\n",
            "86 block4a_se_excite False\n",
            "87 block4a_project_conv False\n",
            "88 block4a_project_bn False\n",
            "89 block4b_expand_conv False\n",
            "90 block4b_expand_bn False\n",
            "91 block4b_expand_activation False\n",
            "92 block4b_dwconv False\n",
            "93 block4b_bn False\n",
            "94 block4b_activation False\n",
            "95 block4b_se_squeeze False\n",
            "96 block4b_se_reshape False\n",
            "97 block4b_se_reduce False\n",
            "98 block4b_se_expand False\n",
            "99 block4b_se_excite False\n",
            "100 block4b_project_conv False\n",
            "101 block4b_project_bn False\n",
            "102 block4b_drop False\n",
            "103 block4b_add False\n",
            "104 block4c_expand_conv False\n",
            "105 block4c_expand_bn False\n",
            "106 block4c_expand_activation False\n",
            "107 block4c_dwconv False\n",
            "108 block4c_bn False\n",
            "109 block4c_activation False\n",
            "110 block4c_se_squeeze False\n",
            "111 block4c_se_reshape False\n",
            "112 block4c_se_reduce False\n",
            "113 block4c_se_expand False\n",
            "114 block4c_se_excite False\n",
            "115 block4c_project_conv False\n",
            "116 block4c_project_bn False\n",
            "117 block4c_drop False\n",
            "118 block4c_add False\n",
            "119 block5a_expand_conv False\n",
            "120 block5a_expand_bn False\n",
            "121 block5a_expand_activation False\n",
            "122 block5a_dwconv False\n",
            "123 block5a_bn False\n",
            "124 block5a_activation False\n",
            "125 block5a_se_squeeze False\n",
            "126 block5a_se_reshape False\n",
            "127 block5a_se_reduce False\n",
            "128 block5a_se_expand False\n",
            "129 block5a_se_excite False\n",
            "130 block5a_project_conv False\n",
            "131 block5a_project_bn False\n",
            "132 block5b_expand_conv False\n",
            "133 block5b_expand_bn False\n",
            "134 block5b_expand_activation False\n",
            "135 block5b_dwconv False\n",
            "136 block5b_bn False\n",
            "137 block5b_activation False\n",
            "138 block5b_se_squeeze False\n",
            "139 block5b_se_reshape False\n",
            "140 block5b_se_reduce False\n",
            "141 block5b_se_expand False\n",
            "142 block5b_se_excite False\n",
            "143 block5b_project_conv False\n",
            "144 block5b_project_bn False\n",
            "145 block5b_drop False\n",
            "146 block5b_add False\n",
            "147 block5c_expand_conv False\n",
            "148 block5c_expand_bn False\n",
            "149 block5c_expand_activation False\n",
            "150 block5c_dwconv False\n",
            "151 block5c_bn False\n",
            "152 block5c_activation False\n",
            "153 block5c_se_squeeze False\n",
            "154 block5c_se_reshape False\n",
            "155 block5c_se_reduce False\n",
            "156 block5c_se_expand False\n",
            "157 block5c_se_excite False\n",
            "158 block5c_project_conv False\n",
            "159 block5c_project_bn False\n",
            "160 block5c_drop False\n",
            "161 block5c_add False\n",
            "162 block6a_expand_conv False\n",
            "163 block6a_expand_bn False\n",
            "164 block6a_expand_activation False\n",
            "165 block6a_dwconv_pad False\n",
            "166 block6a_dwconv False\n",
            "167 block6a_bn False\n",
            "168 block6a_activation False\n",
            "169 block6a_se_squeeze False\n",
            "170 block6a_se_reshape False\n",
            "171 block6a_se_reduce False\n",
            "172 block6a_se_expand False\n",
            "173 block6a_se_excite False\n",
            "174 block6a_project_conv False\n",
            "175 block6a_project_bn False\n",
            "176 block6b_expand_conv False\n",
            "177 block6b_expand_bn False\n",
            "178 block6b_expand_activation False\n",
            "179 block6b_dwconv False\n",
            "180 block6b_bn False\n",
            "181 block6b_activation False\n",
            "182 block6b_se_squeeze False\n",
            "183 block6b_se_reshape False\n",
            "184 block6b_se_reduce False\n",
            "185 block6b_se_expand False\n",
            "186 block6b_se_excite False\n",
            "187 block6b_project_conv False\n",
            "188 block6b_project_bn False\n",
            "189 block6b_drop False\n",
            "190 block6b_add False\n",
            "191 block6c_expand_conv False\n",
            "192 block6c_expand_bn False\n",
            "193 block6c_expand_activation False\n",
            "194 block6c_dwconv False\n",
            "195 block6c_bn False\n",
            "196 block6c_activation False\n",
            "197 block6c_se_squeeze False\n",
            "198 block6c_se_reshape False\n",
            "199 block6c_se_reduce False\n",
            "200 block6c_se_expand False\n",
            "201 block6c_se_excite False\n",
            "202 block6c_project_conv False\n",
            "203 block6c_project_bn False\n",
            "204 block6c_drop False\n",
            "205 block6c_add False\n",
            "206 block6d_expand_conv False\n",
            "207 block6d_expand_bn False\n",
            "208 block6d_expand_activation False\n",
            "209 block6d_dwconv False\n",
            "210 block6d_bn False\n",
            "211 block6d_activation False\n",
            "212 block6d_se_squeeze False\n",
            "213 block6d_se_reshape False\n",
            "214 block6d_se_reduce False\n",
            "215 block6d_se_expand False\n",
            "216 block6d_se_excite False\n",
            "217 block6d_project_conv True\n",
            "218 block6d_project_bn True\n",
            "219 block6d_drop True\n",
            "220 block6d_add True\n",
            "221 block7a_expand_conv True\n",
            "222 block7a_expand_bn True\n",
            "223 block7a_expand_activation True\n",
            "224 block7a_dwconv True\n",
            "225 block7a_bn True\n",
            "226 block7a_activation True\n",
            "227 block7a_se_squeeze True\n",
            "228 block7a_se_reshape True\n",
            "229 block7a_se_reduce True\n",
            "230 block7a_se_expand True\n",
            "231 block7a_se_excite True\n",
            "232 block7a_project_conv True\n",
            "233 block7a_project_bn True\n",
            "234 top_conv True\n",
            "235 top_bn True\n",
            "236 top_activation True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4J1eLFdCB6X"
      },
      "source": [
        "# set the layer to be trainable \n",
        "base_model.trainable=True \n",
        "for layer in base_model.layers[:-20]:\n",
        "  layer.trainable=False\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQoqSf1LDfzK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn5j28I4Cgxg",
        "outputId": "d5078ed6-9bd3-4a40-d539-ba01a32b50be"
      },
      "source": [
        "\n",
        "\n",
        "model_0.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_0.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "data_augumentation (Sequenti (None, None, 224)         0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                12810     \n",
            "=================================================================\n",
            "Total params: 4,062,381\n",
            "Trainable params: 1,363,770\n",
            "Non-trainable params: 2,698,611\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voyqvqTpENH2",
        "outputId": "8324d296-f4fe-4122-c371-92c52ec6e4c7"
      },
      "source": [
        "for layers in model_0.layers:\n",
        "  print(layers,layers.trainable)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f5608bae590> True\n",
            "<keras.engine.sequential.Sequential object at 0x7f5683ba1f90> True\n",
            "<keras.engine.functional.Functional object at 0x7f5680130850> True\n",
            "<keras.layers.pooling.GlobalAveragePooling2D object at 0x7f5608bae5d0> True\n",
            "<keras.layers.core.Dense object at 0x7f568039e3d0> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJzDshqmE28g",
        "outputId": "75390b92-70ad-418d-f395-39c370d10f71"
      },
      "source": [
        "for layers in model_0.layers[2].layers:\n",
        "  print(layers.name,layers.trainable)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_8 False\n",
            "rescaling_4 False\n",
            "normalization_4 False\n",
            "stem_conv_pad False\n",
            "stem_conv False\n",
            "stem_bn False\n",
            "stem_activation False\n",
            "block1a_dwconv False\n",
            "block1a_bn False\n",
            "block1a_activation False\n",
            "block1a_se_squeeze False\n",
            "block1a_se_reshape False\n",
            "block1a_se_reduce False\n",
            "block1a_se_expand False\n",
            "block1a_se_excite False\n",
            "block1a_project_conv False\n",
            "block1a_project_bn False\n",
            "block2a_expand_conv False\n",
            "block2a_expand_bn False\n",
            "block2a_expand_activation False\n",
            "block2a_dwconv_pad False\n",
            "block2a_dwconv False\n",
            "block2a_bn False\n",
            "block2a_activation False\n",
            "block2a_se_squeeze False\n",
            "block2a_se_reshape False\n",
            "block2a_se_reduce False\n",
            "block2a_se_expand False\n",
            "block2a_se_excite False\n",
            "block2a_project_conv False\n",
            "block2a_project_bn False\n",
            "block2b_expand_conv False\n",
            "block2b_expand_bn False\n",
            "block2b_expand_activation False\n",
            "block2b_dwconv False\n",
            "block2b_bn False\n",
            "block2b_activation False\n",
            "block2b_se_squeeze False\n",
            "block2b_se_reshape False\n",
            "block2b_se_reduce False\n",
            "block2b_se_expand False\n",
            "block2b_se_excite False\n",
            "block2b_project_conv False\n",
            "block2b_project_bn False\n",
            "block2b_drop False\n",
            "block2b_add False\n",
            "block3a_expand_conv False\n",
            "block3a_expand_bn False\n",
            "block3a_expand_activation False\n",
            "block3a_dwconv_pad False\n",
            "block3a_dwconv False\n",
            "block3a_bn False\n",
            "block3a_activation False\n",
            "block3a_se_squeeze False\n",
            "block3a_se_reshape False\n",
            "block3a_se_reduce False\n",
            "block3a_se_expand False\n",
            "block3a_se_excite False\n",
            "block3a_project_conv False\n",
            "block3a_project_bn False\n",
            "block3b_expand_conv False\n",
            "block3b_expand_bn False\n",
            "block3b_expand_activation False\n",
            "block3b_dwconv False\n",
            "block3b_bn False\n",
            "block3b_activation False\n",
            "block3b_se_squeeze False\n",
            "block3b_se_reshape False\n",
            "block3b_se_reduce False\n",
            "block3b_se_expand False\n",
            "block3b_se_excite False\n",
            "block3b_project_conv False\n",
            "block3b_project_bn False\n",
            "block3b_drop False\n",
            "block3b_add False\n",
            "block4a_expand_conv False\n",
            "block4a_expand_bn False\n",
            "block4a_expand_activation False\n",
            "block4a_dwconv_pad False\n",
            "block4a_dwconv False\n",
            "block4a_bn False\n",
            "block4a_activation False\n",
            "block4a_se_squeeze False\n",
            "block4a_se_reshape False\n",
            "block4a_se_reduce False\n",
            "block4a_se_expand False\n",
            "block4a_se_excite False\n",
            "block4a_project_conv False\n",
            "block4a_project_bn False\n",
            "block4b_expand_conv False\n",
            "block4b_expand_bn False\n",
            "block4b_expand_activation False\n",
            "block4b_dwconv False\n",
            "block4b_bn False\n",
            "block4b_activation False\n",
            "block4b_se_squeeze False\n",
            "block4b_se_reshape False\n",
            "block4b_se_reduce False\n",
            "block4b_se_expand False\n",
            "block4b_se_excite False\n",
            "block4b_project_conv False\n",
            "block4b_project_bn False\n",
            "block4b_drop False\n",
            "block4b_add False\n",
            "block4c_expand_conv False\n",
            "block4c_expand_bn False\n",
            "block4c_expand_activation False\n",
            "block4c_dwconv False\n",
            "block4c_bn False\n",
            "block4c_activation False\n",
            "block4c_se_squeeze False\n",
            "block4c_se_reshape False\n",
            "block4c_se_reduce False\n",
            "block4c_se_expand False\n",
            "block4c_se_excite False\n",
            "block4c_project_conv False\n",
            "block4c_project_bn False\n",
            "block4c_drop False\n",
            "block4c_add False\n",
            "block5a_expand_conv False\n",
            "block5a_expand_bn False\n",
            "block5a_expand_activation False\n",
            "block5a_dwconv False\n",
            "block5a_bn False\n",
            "block5a_activation False\n",
            "block5a_se_squeeze False\n",
            "block5a_se_reshape False\n",
            "block5a_se_reduce False\n",
            "block5a_se_expand False\n",
            "block5a_se_excite False\n",
            "block5a_project_conv False\n",
            "block5a_project_bn False\n",
            "block5b_expand_conv False\n",
            "block5b_expand_bn False\n",
            "block5b_expand_activation False\n",
            "block5b_dwconv False\n",
            "block5b_bn False\n",
            "block5b_activation False\n",
            "block5b_se_squeeze False\n",
            "block5b_se_reshape False\n",
            "block5b_se_reduce False\n",
            "block5b_se_expand False\n",
            "block5b_se_excite False\n",
            "block5b_project_conv False\n",
            "block5b_project_bn False\n",
            "block5b_drop False\n",
            "block5b_add False\n",
            "block5c_expand_conv False\n",
            "block5c_expand_bn False\n",
            "block5c_expand_activation False\n",
            "block5c_dwconv False\n",
            "block5c_bn False\n",
            "block5c_activation False\n",
            "block5c_se_squeeze False\n",
            "block5c_se_reshape False\n",
            "block5c_se_reduce False\n",
            "block5c_se_expand False\n",
            "block5c_se_excite False\n",
            "block5c_project_conv False\n",
            "block5c_project_bn False\n",
            "block5c_drop False\n",
            "block5c_add False\n",
            "block6a_expand_conv False\n",
            "block6a_expand_bn False\n",
            "block6a_expand_activation False\n",
            "block6a_dwconv_pad False\n",
            "block6a_dwconv False\n",
            "block6a_bn False\n",
            "block6a_activation False\n",
            "block6a_se_squeeze False\n",
            "block6a_se_reshape False\n",
            "block6a_se_reduce False\n",
            "block6a_se_expand False\n",
            "block6a_se_excite False\n",
            "block6a_project_conv False\n",
            "block6a_project_bn False\n",
            "block6b_expand_conv False\n",
            "block6b_expand_bn False\n",
            "block6b_expand_activation False\n",
            "block6b_dwconv False\n",
            "block6b_bn False\n",
            "block6b_activation False\n",
            "block6b_se_squeeze False\n",
            "block6b_se_reshape False\n",
            "block6b_se_reduce False\n",
            "block6b_se_expand False\n",
            "block6b_se_excite False\n",
            "block6b_project_conv False\n",
            "block6b_project_bn False\n",
            "block6b_drop False\n",
            "block6b_add False\n",
            "block6c_expand_conv False\n",
            "block6c_expand_bn False\n",
            "block6c_expand_activation False\n",
            "block6c_dwconv False\n",
            "block6c_bn False\n",
            "block6c_activation False\n",
            "block6c_se_squeeze False\n",
            "block6c_se_reshape False\n",
            "block6c_se_reduce False\n",
            "block6c_se_expand False\n",
            "block6c_se_excite False\n",
            "block6c_project_conv False\n",
            "block6c_project_bn False\n",
            "block6c_drop False\n",
            "block6c_add False\n",
            "block6d_expand_conv False\n",
            "block6d_expand_bn False\n",
            "block6d_expand_activation False\n",
            "block6d_dwconv False\n",
            "block6d_bn False\n",
            "block6d_activation False\n",
            "block6d_se_squeeze False\n",
            "block6d_se_reshape False\n",
            "block6d_se_reduce False\n",
            "block6d_se_expand False\n",
            "block6d_se_excite False\n",
            "block6d_project_conv True\n",
            "block6d_project_bn True\n",
            "block6d_drop True\n",
            "block6d_add True\n",
            "block7a_expand_conv True\n",
            "block7a_expand_bn True\n",
            "block7a_expand_activation True\n",
            "block7a_dwconv True\n",
            "block7a_bn True\n",
            "block7a_activation True\n",
            "block7a_se_squeeze True\n",
            "block7a_se_reshape True\n",
            "block7a_se_reduce True\n",
            "block7a_se_expand True\n",
            "block7a_se_excite True\n",
            "block7a_project_conv True\n",
            "block7a_project_bn True\n",
            "top_conv True\n",
            "top_bn True\n",
            "top_activation True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odBfy44MFMhg",
        "outputId": "9160f7cf-022a-445e-85e8-b49cdd0b1cc3"
      },
      "source": [
        "model_0.trainable_variables"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'block6d_project_conv/kernel:0' shape=(1, 1, 1152, 192) dtype=float32, numpy=\n",
              " array([[[[-0.02386375, -0.0306276 ,  0.08909959, ...,  0.01706599,\n",
              "            0.03644949, -0.06520524],\n",
              "          [ 0.02019947,  0.09646644, -0.08918087, ...,  0.00838837,\n",
              "           -0.00503357, -0.04213767],\n",
              "          [ 0.05015175, -0.00599662, -0.01823547, ...,  0.02438531,\n",
              "           -0.14050964,  0.04840524],\n",
              "          ...,\n",
              "          [ 0.00757436,  0.00585582,  0.00865441, ...,  0.03820141,\n",
              "            0.03841049, -0.02001089],\n",
              "          [ 0.04257223,  0.023178  , -0.00877284, ..., -0.03717634,\n",
              "            0.06671734,  0.00918923],\n",
              "          [-0.03928197,  0.06450572, -0.04263911, ..., -0.06215683,\n",
              "           -0.0602688 ,  0.04657936]]]], dtype=float32)>,\n",
              " <tf.Variable 'block6d_project_bn/gamma:0' shape=(192,) dtype=float32, numpy=\n",
              " array([1.4481882 , 1.6086447 , 1.6297114 , 1.4362782 , 1.9205517 ,\n",
              "        1.6919785 , 1.4104973 , 1.9338481 , 1.4338647 , 1.380879  ,\n",
              "        2.4113564 , 1.5942118 , 1.3759971 , 1.4656335 , 1.0283898 ,\n",
              "        1.5819331 , 1.5461004 , 1.3926693 , 1.4860443 , 1.1527112 ,\n",
              "        1.8164463 , 1.2600769 , 1.7650187 , 1.490105  , 1.0558118 ,\n",
              "        1.4754521 , 1.8907436 , 1.2178302 , 1.5791881 , 0.96004736,\n",
              "        1.4425555 , 1.8891094 , 0.92910135, 2.691596  , 1.773632  ,\n",
              "        1.1394036 , 0.9375796 , 1.5291625 , 2.4342499 , 1.5474782 ,\n",
              "        1.6942959 , 1.5465311 , 1.3553973 , 2.4302402 , 1.8185766 ,\n",
              "        1.5573275 , 1.745397  , 1.4615642 , 0.8563645 , 1.7349399 ,\n",
              "        2.0310776 , 1.4680387 , 1.9066402 , 1.0371469 , 1.7931212 ,\n",
              "        1.7322822 , 1.8905798 , 2.0619726 , 1.9257061 , 1.1928524 ,\n",
              "        1.7253832 , 1.368732  , 2.0965228 , 1.8946799 , 1.3723129 ,\n",
              "        1.800166  , 1.3914542 , 1.5376843 , 1.3542442 , 2.0979936 ,\n",
              "        1.7438662 , 1.8278574 , 1.4602643 , 1.0277171 , 1.652386  ,\n",
              "        0.90416646, 1.543347  , 1.4204525 , 1.862082  , 1.5427662 ,\n",
              "        1.286013  , 1.5398107 , 1.6548972 , 1.3601314 , 1.5486665 ,\n",
              "        1.5016891 , 1.7188404 , 1.5949415 , 1.168398  , 1.491375  ,\n",
              "        0.8149443 , 2.1306427 , 0.88639253, 1.7676616 , 2.062481  ,\n",
              "        1.5109298 , 1.5319358 , 1.4461639 , 1.1831586 , 1.691173  ,\n",
              "        1.9408456 , 1.9236599 , 1.8409994 , 1.6403548 , 1.3609835 ,\n",
              "        1.5259161 , 1.3050445 , 1.4638021 , 2.2445626 , 1.6510946 ,\n",
              "        1.6475213 , 1.5970483 , 1.4922866 , 1.1714302 , 1.7559943 ,\n",
              "        1.7119366 , 1.6232877 , 1.1587753 , 1.4981711 , 1.3524158 ,\n",
              "        1.4711051 , 1.6392627 , 1.4382536 , 1.5338743 , 1.9733504 ,\n",
              "        0.8388671 , 2.3931758 , 1.8599031 , 1.797698  , 0.86493653,\n",
              "        1.1829607 , 0.9685787 , 1.1937437 , 2.1956992 , 2.119765  ,\n",
              "        1.7526585 , 1.5696123 , 1.0298978 , 1.7818502 , 1.7998375 ,\n",
              "        2.091105  , 1.8129753 , 1.6479133 , 1.7435733 , 2.1635716 ,\n",
              "        1.2622944 , 1.4722433 , 1.2822056 , 1.056982  , 0.86168295,\n",
              "        1.3257648 , 1.5162677 , 1.5883652 , 1.5585442 , 1.3541689 ,\n",
              "        1.2300673 , 1.1172986 , 1.4159843 , 1.9860208 , 1.8597938 ,\n",
              "        2.9844217 , 2.2764647 , 1.2154928 , 1.1808074 , 2.090537  ,\n",
              "        1.7489473 , 1.713524  , 1.9316261 , 1.5539798 , 2.3666227 ,\n",
              "        0.8065431 , 2.3883615 , 0.67614806, 1.3533573 , 1.4912791 ,\n",
              "        2.5994332 , 1.5291466 , 1.515056  , 1.8786775 , 1.1449299 ,\n",
              "        1.1554714 , 1.6945794 , 1.0445392 , 1.8933473 , 2.0148578 ,\n",
              "        1.7163643 , 1.7169913 , 1.1430367 , 1.686038  , 1.4689292 ,\n",
              "        1.3141136 , 1.3733464 ], dtype=float32)>,\n",
              " <tf.Variable 'block6d_project_bn/beta:0' shape=(192,) dtype=float32, numpy=\n",
              " array([-0.50060415, -0.33344433, -0.5683245 ,  0.03459018, -0.1975552 ,\n",
              "         0.02412879, -0.11382901, -0.4093994 ,  0.42568788, -0.18053555,\n",
              "         1.3431373 ,  0.4504806 ,  0.17394504, -0.17977317,  0.5067542 ,\n",
              "        -0.2948213 , -0.05623626,  0.19946884,  0.37272313,  0.98963606,\n",
              "        -0.7673428 , -0.21839213,  0.75183725, -0.08364742,  0.287485  ,\n",
              "         0.67404497, -0.02695916, -0.16447048, -0.16748036, -0.2847853 ,\n",
              "        -0.10329273, -0.24538493,  0.27767   , -1.4344265 , -0.5057185 ,\n",
              "        -0.07324647, -0.04187756,  0.05301307, -0.18111542, -0.02221442,\n",
              "        -0.04063678,  0.24848574, -0.92893165, -1.1227491 , -0.1118044 ,\n",
              "        -0.22785889,  0.85437465,  0.27819943, -0.41242462, -0.4872909 ,\n",
              "         0.2947146 ,  0.12587494,  0.15421918,  0.13444832,  0.08097088,\n",
              "         0.5074817 , -0.6970042 ,  0.20336027, -0.6879759 ,  0.31551152,\n",
              "        -0.38630202,  0.24885419, -0.72632605,  0.6795437 , -0.5914929 ,\n",
              "        -0.32023308, -0.03698614, -0.07193651,  0.4487364 ,  0.605577  ,\n",
              "        -0.04167975,  0.06404048, -0.10941344,  0.26330605, -0.34000474,\n",
              "        -0.31652662, -0.39380893, -0.03587855,  0.2270222 ,  0.05604241,\n",
              "        -0.11309212,  0.4167512 ,  0.51721966, -0.28391454, -0.16435067,\n",
              "         0.12639584, -0.18293509, -0.26688617, -0.26389223,  0.09557695,\n",
              "         0.36870974,  0.76246434, -0.04178495, -0.40282932, -0.4464051 ,\n",
              "        -0.3592846 , -0.14971957,  0.1864157 ,  0.5417898 , -0.13403007,\n",
              "         0.27442667, -0.29804263, -0.513222  ,  0.01432444,  0.41724133,\n",
              "        -0.08839896,  0.08568443, -0.24508803,  1.3853406 , -0.24166314,\n",
              "        -0.01303522,  0.14611226,  0.06758655,  0.19132036,  0.13341683,\n",
              "        -0.33652082, -0.08174634, -0.38003632, -0.02361185, -0.2648581 ,\n",
              "         0.2813805 ,  0.15072866, -0.19484638, -0.02091624, -0.0879743 ,\n",
              "        -0.13459457, -1.0216199 ,  0.14569327,  0.02220217,  0.0641478 ,\n",
              "         0.02322456, -0.26211503,  0.21552005,  0.8563808 , -0.6805185 ,\n",
              "         0.7892753 ,  0.55276227,  0.6837675 ,  0.01891262,  0.19480723,\n",
              "        -0.7283014 ,  0.11545903, -0.16352376,  0.17574982, -0.45269322,\n",
              "         0.8873173 ,  0.33740953,  0.06653238, -0.2985721 , -0.20998745,\n",
              "        -0.3533867 ,  0.5825149 ,  0.05322773, -0.15354124, -0.24007307,\n",
              "         0.15073189, -0.591115  , -0.0359728 ,  0.95720685,  0.3685288 ,\n",
              "        -2.0094209 , -0.01529438, -0.18670331,  0.02292369, -0.58389485,\n",
              "         0.5999604 , -0.2998191 , -0.6551543 , -0.31157562, -1.1404114 ,\n",
              "        -0.10166605,  0.04513561,  0.16880667,  0.22094442, -0.29155108,\n",
              "        -0.25667748, -0.47073445, -0.10250545, -0.6304915 , -0.19215004,\n",
              "         0.17973854,  0.12204798, -0.69898444,  0.38409048, -0.11266031,\n",
              "         0.01201748, -0.20411   ,  0.4016488 ,  0.21812814,  0.59174716,\n",
              "         0.13202572, -0.32651287], dtype=float32)>,\n",
              " <tf.Variable 'block7a_expand_conv/kernel:0' shape=(1, 1, 192, 1152) dtype=float32, numpy=\n",
              " array([[[[-0.09411976,  0.10133985, -0.05292047, ..., -0.03265958,\n",
              "           -0.19011253,  0.01031879],\n",
              "          [ 0.05087946, -0.08321749, -0.06859215, ...,  0.04567265,\n",
              "           -0.01702078,  0.01610949],\n",
              "          [ 0.00251027, -0.02385838, -0.03757475, ...,  0.12790461,\n",
              "            0.0795214 , -0.05554584],\n",
              "          ...,\n",
              "          [ 0.05486196,  0.0358608 ,  0.07146738, ..., -0.08957166,\n",
              "            0.03429128, -0.03121823],\n",
              "          [ 0.12071797, -0.11003038, -0.12787686, ...,  0.02312421,\n",
              "            0.00199988,  0.04044404],\n",
              "          [-0.06233951, -0.0849703 ,  0.15936954, ..., -0.10138666,\n",
              "            0.12867132, -0.05361868]]]], dtype=float32)>,\n",
              " <tf.Variable 'block7a_expand_bn/gamma:0' shape=(1152,) dtype=float32, numpy=\n",
              " array([1.1315702 , 0.86602116, 0.65493095, ..., 0.5115943 , 0.38025403,\n",
              "        0.13128388], dtype=float32)>,\n",
              " <tf.Variable 'block7a_expand_bn/beta:0' shape=(1152,) dtype=float32, numpy=\n",
              " array([-0.1987158, -0.8262986, -1.2931018, ..., -0.6601152,  1.1322334,\n",
              "         0.2977623], dtype=float32)>,\n",
              " <tf.Variable 'block7a_dwconv/depthwise_kernel:0' shape=(3, 3, 1152, 1) dtype=float32, numpy=\n",
              " array([[[[ 0.01953526],\n",
              "          [ 0.02701429],\n",
              "          [-0.00724092],\n",
              "          ...,\n",
              "          [ 0.05084503],\n",
              "          [ 0.01376066],\n",
              "          [ 0.05161989]],\n",
              " \n",
              "         [[ 0.09716624],\n",
              "          [ 0.10573541],\n",
              "          [ 0.11561252],\n",
              "          ...,\n",
              "          [ 0.09928499],\n",
              "          [-0.10505044],\n",
              "          [-0.12174696]],\n",
              " \n",
              "         [[ 0.02092162],\n",
              "          [ 0.03347501],\n",
              "          [-0.00651784],\n",
              "          ...,\n",
              "          [ 0.05865708],\n",
              "          [ 0.01716934],\n",
              "          [ 0.0463219 ]]],\n",
              " \n",
              " \n",
              "        [[[ 0.12314421],\n",
              "          [ 0.09644735],\n",
              "          [ 0.14752465],\n",
              "          ...,\n",
              "          [ 0.09812951],\n",
              "          [-0.11644327],\n",
              "          [-0.12895653]],\n",
              " \n",
              "         [[ 0.22098061],\n",
              "          [ 0.19083582],\n",
              "          [ 0.2480653 ],\n",
              "          ...,\n",
              "          [ 0.15747163],\n",
              "          [-0.27982602],\n",
              "          [-0.48339617]],\n",
              " \n",
              "         [[ 0.11993036],\n",
              "          [ 0.09914964],\n",
              "          [ 0.14489716],\n",
              "          ...,\n",
              "          [ 0.09848475],\n",
              "          [-0.11336458],\n",
              "          [-0.12663695]]],\n",
              " \n",
              " \n",
              "        [[[ 0.00708438],\n",
              "          [ 0.02545464],\n",
              "          [ 0.00955209],\n",
              "          ...,\n",
              "          [ 0.0575304 ],\n",
              "          [-0.00647084],\n",
              "          [ 0.04443246]],\n",
              " \n",
              "         [[ 0.09394294],\n",
              "          [ 0.08155358],\n",
              "          [ 0.15850787],\n",
              "          ...,\n",
              "          [ 0.11800287],\n",
              "          [-0.11521706],\n",
              "          [-0.0980774 ]],\n",
              " \n",
              "         [[ 0.00399475],\n",
              "          [ 0.02306843],\n",
              "          [ 0.01514247],\n",
              "          ...,\n",
              "          [ 0.06263041],\n",
              "          [-0.01067638],\n",
              "          [ 0.04934606]]]], dtype=float32)>,\n",
              " <tf.Variable 'block7a_bn/gamma:0' shape=(1152,) dtype=float32, numpy=\n",
              " array([0.9203655, 0.9430805, 1.0441844, ..., 1.5056304, 1.9557922,\n",
              "        1.8080177], dtype=float32)>,\n",
              " <tf.Variable 'block7a_bn/beta:0' shape=(1152,) dtype=float32, numpy=\n",
              " array([-0.1153497 , -0.41761503, -0.33573687, ..., -2.1652517 ,\n",
              "        -1.318019  , -0.28519085], dtype=float32)>,\n",
              " <tf.Variable 'block7a_se_reduce/kernel:0' shape=(1, 1, 1152, 48) dtype=float32, numpy=\n",
              " array([[[[-0.05485657,  0.07178846,  0.01534605, ..., -0.09284662,\n",
              "            0.0104828 , -0.02693838],\n",
              "          [-0.03157939,  0.02819107, -0.05579546, ...,  0.00487578,\n",
              "            0.12001809, -0.06901816],\n",
              "          [-0.07792544,  0.12601745,  0.03935236, ...,  0.03086486,\n",
              "           -0.01581392,  0.1306234 ],\n",
              "          ...,\n",
              "          [-0.07692936,  0.19920062,  0.17471024, ...,  0.03312391,\n",
              "           -0.04528928, -0.09214652],\n",
              "          [ 0.01010198,  0.06855008,  0.05820991, ...,  0.00131649,\n",
              "           -0.08952942, -0.00476829],\n",
              "          [ 0.03583075, -0.01228165,  0.04561347, ..., -0.00822134,\n",
              "           -0.07354517, -0.06507882]]]], dtype=float32)>,\n",
              " <tf.Variable 'block7a_se_reduce/bias:0' shape=(48,) dtype=float32, numpy=\n",
              " array([-0.10886215, -0.13624744, -0.15257476,  0.14799541, -0.08512902,\n",
              "        -0.12059905, -0.08779966, -0.08187538, -0.06925284, -0.12518929,\n",
              "        -0.0819265 , -0.1259736 , -0.09993652, -0.10109923, -0.13398036,\n",
              "        -0.09867296, -0.09382621, -0.11011569, -0.1063069 , -0.09003814,\n",
              "        -0.04766154, -0.06743164, -0.13778378, -0.10579358, -0.10130141,\n",
              "        -0.13948615,  0.13246794, -0.03255463, -0.11809722, -0.04813838,\n",
              "        -0.13148174, -0.05429332, -0.0448516 , -0.11129897, -0.08523702,\n",
              "        -0.13361962, -0.07146074, -0.13821687, -0.0614575 , -0.02393492,\n",
              "        -0.08265438, -0.13204956, -0.10251977, -0.12446474, -0.1350065 ,\n",
              "        -0.06927117, -0.07627591, -0.08064308], dtype=float32)>,\n",
              " <tf.Variable 'block7a_se_expand/kernel:0' shape=(1, 1, 48, 1152) dtype=float32, numpy=\n",
              " array([[[[ 0.01703347, -0.09556078, -0.12866898, ..., -0.11176323,\n",
              "           -0.12041699,  0.07214174],\n",
              "          [ 0.11851509,  0.09440814, -0.07513665, ..., -0.10720892,\n",
              "            0.15331012,  0.00920153],\n",
              "          [-0.03525457, -0.05621038,  0.03370081, ...,  0.0058019 ,\n",
              "            0.08038238,  0.02380909],\n",
              "          ...,\n",
              "          [-0.16428104,  0.14296436, -0.07728611, ..., -0.03546136,\n",
              "            0.03369582, -0.19963196],\n",
              "          [-0.01133208, -0.0060606 ,  0.10776694, ...,  0.01572948,\n",
              "           -0.06349678, -0.05537278],\n",
              "          [-0.09189203, -0.05271737, -0.08292874, ..., -0.03266691,\n",
              "           -0.15144289, -0.13922407]]]], dtype=float32)>,\n",
              " <tf.Variable 'block7a_se_expand/bias:0' shape=(1152,) dtype=float32, numpy=\n",
              " array([ 0.04515592,  0.0518708 ,  0.08215576, ..., -0.02809454,\n",
              "         0.06679371,  0.14091711], dtype=float32)>,\n",
              " <tf.Variable 'block7a_project_conv/kernel:0' shape=(1, 1, 1152, 320) dtype=float32, numpy=\n",
              " array([[[[ 0.04719412, -0.03508057,  0.18866068, ...,  0.00667723,\n",
              "            0.01607844, -0.06703078],\n",
              "          [-0.10309057,  0.01945817,  0.03923143, ..., -0.09136088,\n",
              "            0.07520416,  0.09395675],\n",
              "          [-0.0786793 ,  0.02817695, -0.03047303, ...,  0.01593926,\n",
              "            0.13013661, -0.05727762],\n",
              "          ...,\n",
              "          [ 0.01056576, -0.02389853,  0.15035501, ...,  0.04682408,\n",
              "            0.03543943, -0.0752975 ],\n",
              "          [-0.06144901, -0.0928897 ,  0.05499939, ...,  0.16682369,\n",
              "            0.08615127, -0.02209447],\n",
              "          [-0.04315694,  0.1413447 ,  0.00528443, ..., -0.00220996,\n",
              "            0.1894294 , -0.11107358]]]], dtype=float32)>,\n",
              " <tf.Variable 'block7a_project_bn/gamma:0' shape=(320,) dtype=float32, numpy=\n",
              " array([2.6341524, 3.6408505, 2.6395326, 2.6145833, 2.6313312, 2.6202953,\n",
              "        2.5319185, 2.5870585, 2.688308 , 2.6000342, 2.9978335, 2.537907 ,\n",
              "        2.6381385, 2.716591 , 2.558281 , 2.4929833, 2.644765 , 2.462597 ,\n",
              "        2.6660817, 2.5237637, 2.6011422, 2.824746 , 2.5168786, 2.5305552,\n",
              "        2.7185206, 2.7899334, 2.682837 , 2.5672472, 2.4950414, 2.607678 ,\n",
              "        2.6045194, 2.5780609, 2.63664  , 2.5805535, 2.5575125, 2.5273108,\n",
              "        2.5634987, 2.7832053, 2.6418092, 2.604934 , 2.5325363, 2.6006708,\n",
              "        2.6354814, 2.5668874, 2.7951095, 2.646076 , 3.0281844, 2.6361535,\n",
              "        3.1250885, 2.635435 , 2.5462308, 2.6689003, 2.5725474, 2.5831702,\n",
              "        2.5835443, 2.656816 , 2.5504594, 2.6580045, 2.642674 , 2.548922 ,\n",
              "        2.5658593, 2.5088289, 2.8326697, 2.6741598, 2.724444 , 2.6740642,\n",
              "        2.6301656, 2.6501355, 2.5464098, 2.584042 , 2.5088935, 2.6053326,\n",
              "        2.548359 , 2.742098 , 2.6033902, 2.5825214, 2.6483955, 2.685057 ,\n",
              "        2.6903856, 2.7595356, 2.6767306, 2.650072 , 2.6561706, 2.6387742,\n",
              "        2.5386903, 2.6601446, 2.585036 , 2.581829 , 2.493314 , 2.5478692,\n",
              "        2.7056026, 2.5470285, 2.6166646, 2.7911394, 2.5091803, 2.5457087,\n",
              "        2.4962032, 2.616603 , 2.8938844, 2.5239155, 2.5611029, 2.5762894,\n",
              "        2.6258383, 2.7690558, 2.6246526, 2.573153 , 2.63151  , 2.6664348,\n",
              "        2.5510879, 2.633915 , 2.5973866, 2.6333516, 2.5894468, 2.5375085,\n",
              "        2.7006404, 2.6648164, 2.5562012, 2.6261616, 2.5598128, 2.515569 ,\n",
              "        2.643523 , 2.6532161, 2.7102292, 2.5004933, 2.8885357, 2.5730307,\n",
              "        2.6309655, 2.5566099, 2.542208 , 2.5430515, 2.95321  , 2.530806 ,\n",
              "        2.6387343, 2.610428 , 2.580837 , 2.6031556, 2.668818 , 2.549356 ,\n",
              "        2.6471393, 2.5472634, 2.669148 , 2.59522  , 2.6507857, 2.4828112,\n",
              "        2.601118 , 2.593023 , 2.549623 , 2.534933 , 2.7077003, 2.5183656,\n",
              "        2.6026828, 2.985571 , 2.6405106, 2.7155428, 2.5788558, 2.6546528,\n",
              "        2.5677054, 2.4542222, 2.7947254, 2.5911338, 2.6567724, 2.5698543,\n",
              "        2.50019  , 2.5938528, 2.6083398, 2.5553062, 2.5281339, 2.5907693,\n",
              "        2.5921338, 2.6407883, 2.5940228, 2.6011744, 2.6939318, 2.5788543,\n",
              "        2.611848 , 2.5353673, 2.5492253, 2.6692536, 2.5442774, 2.6057358,\n",
              "        2.545667 , 2.699785 , 2.5898273, 2.6510255, 2.6357298, 2.5392187,\n",
              "        3.0744135, 2.5465763, 2.62727  , 2.8991907, 2.6765053, 2.5408316,\n",
              "        2.6696007, 2.663587 , 2.6330073, 2.6307907, 2.557663 , 2.6597102,\n",
              "        2.7168522, 3.0360131, 2.4636025, 2.5911775, 2.6008296, 2.6731155,\n",
              "        2.6936364, 2.716485 , 2.680393 , 2.7018907, 2.7021012, 2.5174494,\n",
              "        2.604642 , 2.6076188, 2.6755745, 2.5452864, 2.5664885, 2.8462067,\n",
              "        2.7362747, 2.666304 , 2.5056198, 2.5951312, 2.5824764, 2.6146016,\n",
              "        2.642559 , 2.5692267, 2.792615 , 2.6337516, 2.4910922, 2.6466959,\n",
              "        2.6380413, 2.5529966, 2.565908 , 2.5560148, 2.640346 , 2.6173239,\n",
              "        2.6475196, 2.6759052, 3.218808 , 2.5925794, 2.5743115, 2.6601744,\n",
              "        2.6724327, 2.631072 , 2.562081 , 2.5806832, 2.512028 , 2.6604302,\n",
              "        2.5478892, 2.5730498, 2.6972325, 2.5915775, 2.6661477, 2.6339667,\n",
              "        2.6636207, 2.5320785, 2.6257393, 2.622644 , 2.508248 , 2.6330373,\n",
              "        2.599642 , 2.6596751, 2.6126783, 2.6051974, 2.652374 , 2.6319253,\n",
              "        2.8959923, 2.6422274, 2.6246538, 2.4762268, 2.631236 , 2.4831147,\n",
              "        2.6260679, 2.519754 , 2.619554 , 2.8796465, 2.614829 , 2.58701  ,\n",
              "        2.5688565, 2.6110027, 2.6058009, 2.5786552, 2.6547408, 2.5492873,\n",
              "        2.6010828, 2.8261983, 2.5328765, 2.689091 , 2.5229828, 2.5879102,\n",
              "        2.7365847, 2.7272425, 2.6959665, 2.6330662, 2.5203118, 2.688423 ,\n",
              "        2.5512888, 3.3626828, 2.5781293, 2.50825  , 2.5737724, 2.621484 ,\n",
              "        2.6324031, 2.6176171, 2.5813835, 2.5144784, 2.633849 , 2.8199816,\n",
              "        2.6682093, 2.599474 , 2.6375234, 2.684862 , 2.525223 , 2.6976318,\n",
              "        2.6058314, 2.5276728, 2.4987195, 2.572669 , 2.5587776, 2.5677974,\n",
              "        2.838972 , 2.619664 ], dtype=float32)>,\n",
              " <tf.Variable 'block7a_project_bn/beta:0' shape=(320,) dtype=float32, numpy=\n",
              " array([ 2.72746431e-04, -4.64200834e-03,  1.81363500e-03, -1.35792862e-03,\n",
              "        -1.83621727e-04,  7.23875011e-04, -7.06277788e-04, -3.28818336e-04,\n",
              "        -1.00322848e-03,  5.77372033e-04, -3.32189701e-03, -8.64792033e-04,\n",
              "         1.79181120e-03, -8.18454195e-04, -1.69087423e-03,  2.51508714e-03,\n",
              "        -1.26882526e-03, -3.69476293e-05, -2.75014690e-03, -3.24349292e-03,\n",
              "         2.12383200e-03, -9.11651237e-04, -2.34528631e-03, -1.68305065e-03,\n",
              "        -7.17351562e-04,  2.03338059e-04, -1.06290297e-03, -1.05257204e-03,\n",
              "         7.56997324e-04,  8.66741582e-04,  4.24314709e-03,  5.80201682e-04,\n",
              "        -1.42630236e-03,  3.64625268e-03,  1.12341705e-03,  1.69936311e-03,\n",
              "         1.08880980e-03,  4.06244246e-04,  1.67966017e-03, -3.07304901e-04,\n",
              "         2.56448926e-04, -2.74889544e-03, -2.60693108e-04,  6.29616028e-04,\n",
              "         5.18684392e-04,  5.06498793e-04, -1.75745424e-03, -2.50845333e-03,\n",
              "         3.29580111e-03,  2.34114681e-03,  1.78862875e-03, -1.96675933e-03,\n",
              "        -2.85300863e-04,  2.95514881e-04,  1.76551077e-03,  2.14295986e-04,\n",
              "        -2.74702528e-04, -4.98560366e-05, -2.33496467e-05,  6.49673748e-05,\n",
              "         3.62340477e-04, -9.65728366e-04, -2.40365812e-03, -3.28422553e-04,\n",
              "         1.72259891e-03, -9.60275298e-04, -1.24948169e-03, -1.23629603e-03,\n",
              "        -4.82999487e-04,  1.66278379e-03, -1.42891321e-03, -8.51270393e-04,\n",
              "         2.50486657e-03,  1.03739847e-03,  4.44977719e-04, -4.01280500e-04,\n",
              "        -6.51122653e-04,  7.47022335e-04, -1.48657290e-03,  5.63821697e-04,\n",
              "        -2.27600569e-03,  1.02134841e-03,  1.50884001e-03, -4.78561968e-04,\n",
              "        -2.13380903e-04,  3.12323740e-04,  1.69344270e-03,  7.68164638e-04,\n",
              "        -1.42305926e-03, -1.06511544e-03,  8.57689520e-05, -1.03630626e-03,\n",
              "        -5.28990058e-04, -6.56761054e-04, -1.05450675e-03,  1.19510374e-03,\n",
              "        -3.83046397e-04, -2.39993151e-05, -6.99702534e-04, -1.11313257e-03,\n",
              "         1.15426502e-03, -3.16569209e-03,  1.56251244e-05, -5.30554564e-04,\n",
              "        -1.35117490e-03, -1.99875431e-04, -1.27230806e-03,  3.45696841e-04,\n",
              "        -1.73765479e-03,  8.10689293e-04, -7.09120708e-04,  1.19463378e-03,\n",
              "        -1.29504187e-03, -1.42769760e-03, -2.05490855e-03,  3.33959106e-05,\n",
              "        -9.67560452e-04,  2.18152488e-03,  2.38515713e-05,  4.46808335e-05,\n",
              "        -2.04296876e-03, -1.20915414e-03, -9.56242220e-05,  4.59675764e-04,\n",
              "         3.40061216e-03,  2.13403418e-03, -5.79986838e-04,  1.29770138e-03,\n",
              "        -1.09179609e-03,  9.54744522e-04, -8.50354671e-04, -1.00062031e-03,\n",
              "         1.42553748e-04,  3.43387743e-04, -5.74955542e-04, -2.38789900e-04,\n",
              "        -1.63314794e-03,  1.01994854e-04,  2.63368245e-03,  1.79869402e-03,\n",
              "        -1.25590130e-03, -2.92626093e-03,  9.38380021e-04, -3.11836222e-04,\n",
              "        -4.31053893e-04, -1.59043982e-03,  1.84826949e-03,  1.48812158e-03,\n",
              "        -2.77693220e-03, -8.86596739e-04, -2.36758046e-04, -7.58587732e-04,\n",
              "         1.39371923e-03, -4.49905143e-04,  5.05587144e-04, -9.97542636e-04,\n",
              "         1.03000528e-03,  2.86184740e-03, -1.79313810e-03, -6.55176118e-04,\n",
              "        -2.65727611e-03,  7.20865792e-04,  1.30724453e-03, -4.23565325e-05,\n",
              "         6.62169245e-04, -4.66128025e-04,  2.81012943e-03,  1.82552508e-03,\n",
              "         5.87477058e-04, -4.03790065e-04,  8.74075748e-04,  7.78581234e-05,\n",
              "         1.90386223e-03, -1.54897827e-03,  2.25501688e-04,  5.10995567e-04,\n",
              "         2.55123922e-03,  8.13688268e-04, -7.14337279e-04, -5.06902405e-04,\n",
              "         2.85416422e-03,  7.83873023e-04, -1.10656860e-04,  9.32446972e-04,\n",
              "         2.40951893e-03, -6.86718326e-04, -2.52255704e-03,  2.18124787e-05,\n",
              "         1.05487206e-05,  8.27186217e-04, -1.75172405e-03, -1.25424110e-03,\n",
              "         8.82197171e-04, -5.65536728e-04, -1.00640114e-03, -3.75324744e-04,\n",
              "         1.51518488e-03, -1.22928934e-04,  8.04806245e-04,  4.69992170e-04,\n",
              "        -5.85276866e-04, -1.16747025e-04, -3.51934647e-03,  1.32238166e-03,\n",
              "         1.72750279e-03,  2.94423138e-04,  2.98701430e-04,  4.09114582e-04,\n",
              "        -5.18784160e-04, -2.73050228e-03,  1.59792858e-03,  2.05026925e-04,\n",
              "         7.29332387e-04, -8.44324881e-04,  1.73368491e-03, -1.31481164e-03,\n",
              "        -1.38368423e-03,  3.16325552e-03,  1.51809235e-03,  8.39646265e-04,\n",
              "         6.18721606e-05, -2.25067860e-03, -1.54738067e-04,  7.56336085e-04,\n",
              "        -1.71400257e-03,  6.03145338e-04, -5.99783496e-04,  9.78035154e-04,\n",
              "        -2.15801597e-03,  9.26407811e-04,  6.17332407e-04,  2.00839248e-03,\n",
              "         3.08294198e-03, -7.05075916e-04,  3.08018411e-03, -2.07686680e-03,\n",
              "        -3.42484983e-03,  8.07445089e-04, -1.29282055e-03, -1.24681287e-03,\n",
              "         6.63550978e-04,  1.38722942e-03, -1.00464269e-03,  2.45917181e-04,\n",
              "        -1.47426047e-03, -2.40818423e-04,  2.99509428e-03,  1.09945354e-03,\n",
              "         8.59148684e-04,  1.50627500e-06, -1.17584574e-03,  4.68704355e-04,\n",
              "         8.43120288e-05,  1.58117816e-03,  1.44869217e-03, -1.08577078e-03,\n",
              "        -9.88185639e-04,  2.09095539e-03,  1.32484653e-03, -1.08445913e-03,\n",
              "        -8.18771659e-04, -1.73332344e-03, -6.66451058e-04, -1.59535231e-03,\n",
              "         3.21470387e-03,  1.90356874e-03,  7.54604407e-04, -2.53299979e-04,\n",
              "         1.34878664e-03, -1.87308283e-03,  1.15370855e-03, -1.05404225e-03,\n",
              "        -1.19788572e-03,  1.14590931e-03,  1.14154675e-04, -5.62238798e-04,\n",
              "         1.96290808e-03,  8.19200242e-04, -1.13923859e-03, -1.30361354e-03,\n",
              "         1.50869356e-03, -1.18403800e-03, -2.32256460e-03,  1.89215309e-04,\n",
              "        -4.54480432e-05, -1.98359881e-03,  1.85492670e-03, -2.23364055e-04,\n",
              "        -8.34366656e-04,  2.03655963e-03,  1.67561357e-03,  1.62004714e-03,\n",
              "        -3.21354310e-04,  3.61894118e-03, -5.57434803e-04, -1.67479762e-03,\n",
              "         1.03459624e-03,  4.82435600e-04, -2.24323105e-03, -1.16618583e-03,\n",
              "         1.39774487e-03, -3.93694296e-04,  1.31923391e-03, -8.33242026e-04,\n",
              "        -1.68927254e-05, -2.22254661e-03, -4.09675704e-04,  2.92616361e-03,\n",
              "        -1.78410482e-04, -1.21830043e-03,  3.88241722e-03,  7.66222889e-04,\n",
              "        -1.43284255e-04, -1.88554521e-03,  8.52050260e-04,  1.40042137e-03,\n",
              "         2.37329234e-03,  7.15036993e-04, -2.30495381e-04,  3.50229093e-03],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'top_conv/kernel:0' shape=(1, 1, 320, 1280) dtype=float32, numpy=\n",
              " array([[[[ 0.010654  ,  0.04302309, -0.05814039, ...,  0.07820047,\n",
              "            0.09309781,  0.13512692],\n",
              "          [ 0.18291403,  0.0635317 ,  0.1210966 , ...,  0.10852515,\n",
              "            0.09180524,  0.25709218],\n",
              "          [-0.01965742,  0.02730735,  0.02497241, ...,  0.10817309,\n",
              "            0.11124102,  0.03874104],\n",
              "          ...,\n",
              "          [ 0.16707249,  0.0034612 , -0.04011405, ...,  0.07070784,\n",
              "           -0.03778364,  0.04866563],\n",
              "          [-0.03250833, -0.03533007, -0.08403775, ..., -0.04473848,\n",
              "           -0.06186406,  0.05368444],\n",
              "          [ 0.14157134, -0.01509961, -0.20079431, ..., -0.10574265,\n",
              "           -0.04939263,  0.04458737]]]], dtype=float32)>,\n",
              " <tf.Variable 'top_bn/gamma:0' shape=(1280,) dtype=float32, numpy=\n",
              " array([2.656564 , 2.543096 , 2.3632998, ..., 2.7232573, 2.503377 ,\n",
              "        2.161115 ], dtype=float32)>,\n",
              " <tf.Variable 'top_bn/beta:0' shape=(1280,) dtype=float32, numpy=\n",
              " array([-2.2949498, -2.3487396, -2.0764754, ..., -2.4685047, -2.2737474,\n",
              "        -1.4324068], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/kernel:0' shape=(1280, 10) dtype=float32, numpy=\n",
              " array([[-0.0031624 , -0.04947811, -0.0014374 , ..., -0.104511  ,\n",
              "         -0.08558203,  0.006635  ],\n",
              "        [-0.08512115, -0.04989177, -0.0699514 , ...,  0.19347993,\n",
              "         -0.09288654,  0.1293589 ],\n",
              "        [-0.0762923 ,  0.08512655,  0.05763372, ..., -0.01984908,\n",
              "         -0.14231172,  0.01356585],\n",
              "        ...,\n",
              "        [-0.02546541,  0.00408687,  0.01691389, ...,  0.01973594,\n",
              "          0.1110546 ,  0.15810934],\n",
              "        [ 0.02428994,  0.01109017, -0.11868496, ..., -0.0843202 ,\n",
              "          0.08728807,  0.01178777],\n",
              "        [ 0.01055631, -0.02432728,  0.05481138, ..., -0.04755889,\n",
              "          0.03897712,  0.04159982]], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
              " array([ 0.01400448, -0.01324611,  0.0083894 , -0.02088975, -0.00699646,\n",
              "         0.03021527,  0.01436733, -0.00422715, -0.02141483, -0.00800484],\n",
              "       dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7cLwC-lFhtn",
        "outputId": "99eb174e-3ebb-4b19-e9f7-b225fbe798d7"
      },
      "source": [
        "# fit the model zero \n",
        "epochs=intial_epoch+10\n",
        "history_0_last_10=model_0.fit(train_data_10_percent,\n",
        "                              steps_per_epoch=len(train_data_10_percent),\n",
        "                              validation_data=test_data,\n",
        "                              validation_steps=int(len(test_data)*0.25),\n",
        "                              batch_size=32,\n",
        "                              initial_epoch=history_0.epoch[-1],\n",
        "                              callbacks=[checkpoint_callback],\n",
        "                              epochs=epochs)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224), dtype=tf.float32, name='random_flip_input'), name='random_flip_input', description=\"created by layer 'random_flip_input'\"), but it was called on an input with incompatible shape (None, 224, 224, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 224, 224) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224), dtype=tf.float32, name='random_flip_input'), name='random_flip_input', description=\"created by layer 'random_flip_input'\"), but it was called on an input with incompatible shape (None, 224, 224, 3).\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.5802 - accuracy: 0.7987WARNING:tensorflow:Model was constructed with shape (None, 224, 224) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224), dtype=tf.float32, name='random_flip_input'), name='random_flip_input', description=\"created by layer 'random_flip_input'\"), but it was called on an input with incompatible shape (None, 224, 224, 3).\n",
            "24/24 [==============================] - 24s 620ms/step - loss: 0.5802 - accuracy: 0.7987 - val_loss: 0.5614 - val_accuracy: 0.8355\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.44336\n",
            "Epoch 6/15\n",
            "24/24 [==============================] - 12s 486ms/step - loss: 0.2517 - accuracy: 0.9280 - val_loss: 0.4565 - val_accuracy: 0.8684\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.44336\n",
            "Epoch 7/15\n",
            "24/24 [==============================] - 11s 465ms/step - loss: 0.1838 - accuracy: 0.9453 - val_loss: 0.4631 - val_accuracy: 0.8602\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.44336\n",
            "Epoch 8/15\n",
            "24/24 [==============================] - 11s 457ms/step - loss: 0.1493 - accuracy: 0.9533 - val_loss: 0.4573 - val_accuracy: 0.8602\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.44336\n",
            "Epoch 9/15\n",
            "24/24 [==============================] - 12s 501ms/step - loss: 0.1039 - accuracy: 0.9707 - val_loss: 0.4981 - val_accuracy: 0.8668\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.44336\n",
            "Epoch 10/15\n",
            "24/24 [==============================] - 11s 436ms/step - loss: 0.0940 - accuracy: 0.9667 - val_loss: 0.5553 - val_accuracy: 0.8470\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.44336\n",
            "Epoch 11/15\n",
            "24/24 [==============================] - 10s 404ms/step - loss: 0.0633 - accuracy: 0.9827 - val_loss: 0.5983 - val_accuracy: 0.8470\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.44336\n",
            "Epoch 12/15\n",
            "24/24 [==============================] - 11s 456ms/step - loss: 0.0663 - accuracy: 0.9800 - val_loss: 0.5144 - val_accuracy: 0.8684\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.44336\n",
            "Epoch 13/15\n",
            "24/24 [==============================] - 12s 451ms/step - loss: 0.0538 - accuracy: 0.9840 - val_loss: 0.6243 - val_accuracy: 0.8503\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.44336\n",
            "Epoch 14/15\n",
            "24/24 [==============================] - 11s 432ms/step - loss: 0.0581 - accuracy: 0.9827 - val_loss: 0.4969 - val_accuracy: 0.8553\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.44336\n",
            "Epoch 15/15\n",
            "24/24 [==============================] - 11s 428ms/step - loss: 0.0626 - accuracy: 0.9840 - val_loss: 0.6677 - val_accuracy: 0.8487\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.44336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfOGwjjFGwuC"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}